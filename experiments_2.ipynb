{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.retiro_model import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear Attention\n",
      "Using Linear Attention\n",
      "Using Linear Attention\n"
     ]
    }
   ],
   "source": [
    "model = GNOT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x   = torch.rand([4,100,2]).requires_grad_(True)\n",
    "x_i = torch.rand([4,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(x,inputs=x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils.navier_stokes_autograd import ns_pde_autograd_loss, ns_pde_autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pde_losses, derivatives = ns_pde_autograd(x,output,Re=x_i*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the autograd works for multiple epochs and loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils.dynamic_loss_balancing import RELOBRALO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 100])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pde_losses[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Linear Attention\n",
      "Using Linear Attention\n",
      "Using Linear Attention\n",
      "0 0.5566155910491943 0.31936296820640564 0.09534536302089691 0.09351211786270142 0.047878675162792206\n",
      "1 4.7147722244262695 2.316746950149536 0.07103215157985687 1.460742473602295 0.8642853498458862\n",
      "2 10.846285820007324 7.885335922241211 1.3167592287063599 1.2047524452209473 0.4393516778945923\n",
      "3 12.460443496704102 7.230006694793701 0.15954603254795074 2.7476274967193604 2.3297910690307617\n",
      "4 7.7360148429870605 7.592007637023926 0.028351102024316788 0.004698147065937519 0.09453578293323517\n",
      "5 4.3070292472839355 4.262635707855225 0.004743481054902077 0.02526351436972618 0.009613150730729103\n",
      "6 0.7523016929626465 0.7277841567993164 0.010380929335951805 0.005406122654676437 0.008629374206066132\n",
      "7 3.601954936981201 3.440579414367676 0.05126090347766876 0.0296825859695673 0.08318401128053665\n",
      "8 0.5972688794136047 0.5478684902191162 0.010435030795633793 0.0310489721596241 0.00894132163375616\n",
      "9 1.1194519996643066 0.9910036325454712 0.020880382508039474 0.013613814488053322 0.09626136720180511\n",
      "10 1.3569947481155396 1.212962031364441 0.013809243217110634 0.014621078036725521 0.11732204258441925\n",
      "11 0.3677282929420471 0.2916361689567566 0.011217181570827961 0.005643951706588268 0.059762872755527496\n",
      "12 0.4812364876270294 0.44009944796562195 0.008902386762201786 0.009464043192565441 0.024152347818017006\n",
      "13 0.8540409803390503 0.8373743295669556 0.005227500572800636 0.008335593156516552 0.003433024976402521\n",
      "14 0.5175175070762634 0.5050054788589478 0.0026597625110298395 0.0017971635097637773 0.008703063242137432\n",
      "15 0.13346146047115326 0.06062077730894089 0.00418279180303216 0.007398680318146944 0.06083476543426514\n",
      "16 0.27916616201400757 0.18773864209651947 0.006203930824995041 0.01495971530675888 0.06961766630411148\n",
      "17 0.16117145121097565 0.13611455261707306 0.005666085984557867 0.0023848768323659897 0.016876891255378723\n",
      "18 0.16296467185020447 0.15446388721466064 0.006746768485754728 0.00018020288553088903 0.0014769874978810549\n",
      "19 0.056854404509067535 0.047265518456697464 0.005717164371162653 0.0002295331214554608 0.0036368025466799736\n",
      "20 0.07172370702028275 0.0609559565782547 0.0041563864797353745 0.00017204174946527928 0.006451957393437624\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-af1aedc92975>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mtotal_losses_bal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrelobralo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mall_losses_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mtotal_losses_bal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Noahc\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m             )\n\u001b[1;32m--> 487\u001b[1;33m         torch.autograd.backward(\n\u001b[0m\u001b[0;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         )\n",
      "\u001b[1;32mc:\\Users\\Noahc\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GNOT()\n",
    "epochs = 100\n",
    "relobralo = RELOBRALO(device='cpu')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                                    betas=(0.9, 0.999), \n",
    "                                    lr=0.01,\n",
    "                                    weight_decay=0.00005\n",
    "                                    )\n",
    "loss_function = torch.nn.MSELoss()\n",
    "x   = torch.rand([4,100,2])#.requires_grad_(True)\n",
    "x_i = torch.rand([4,1,1])\n",
    "\n",
    "for e in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    x_in = x.clone()\n",
    "    x_in.requires_grad = True\n",
    "\n",
    "    output = model(x_in,inputs=x_i)\n",
    "\n",
    "    supervised_loss = [loss_function(output,torch.ones_like(output))]\n",
    "    pde_loss_list = ns_pde_autograd_loss(x_in,output,Re=x_i*10)\n",
    "\n",
    "    all_losses_list = supervised_loss + pde_loss_list\n",
    "\n",
    "\n",
    "    total_losses_bal = relobralo(loss_list=all_losses_list)\n",
    "    total_losses_bal.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(e, total_losses_bal.item(), all_losses_list[0].item(), all_losses_list[1].item(), all_losses_list[2].item(), all_losses_list[3].item())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0373, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_losses_list)/len(all_losses_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict3 = dict.fromkeys(['Supervised Loss','PDE 1','PDE 2'],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict3['Supervised Loss'].append(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Supervised Loss': [0.5, 0.5], 'PDE 1': [0.5, 0.5], 'PDE 2': [0.5, 0.5]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {\"losses\" : 10, \"pde1\": 20}\n",
    "dict2 = {\"losses\" : 30, \"pde1\": 420}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-b19af9687968>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdict1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdict2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "dict1dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class total_loss_list():\n",
    "    def __init__(self):\n",
    "        super(total_loss_list, self).__init__()\n",
    "        self.dictionary = dict()\n",
    "        \n",
    "    def update(self, loss_list):\n",
    "        for key_name in loss_list.keys():\n",
    "            if key_name not in self.dictionary.keys():\n",
    "                self.dictionary[key_name] = []\n",
    "            self.dictionary[key_name].append(loss_list[key_name])\n",
    "    \n",
    "    def fetch_list(self):\n",
    "        return self.dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_list = total_loss_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss_list.update(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.total_loss_list"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {}\n",
    "dict1['hello'] = 0\n",
    "dict1['vd'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hello': 0, 'vd': 12}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = [ 1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['hi', 'bill', 'say']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hibal': 1, 'billbal': 2, 'saybal': 3}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{keys[i]+'bal':j for i,j in enumerate(losses)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class total_loss_list():\n",
    "    def __init__(self):\n",
    "        super(total_loss_list, self).__init__()\n",
    "        self.dictionary = dict()\n",
    "        \n",
    "    def update(self, loss_dict):\n",
    "        for key_name in loss_dict.keys():\n",
    "            if key_name not in self.dictionary.keys():\n",
    "                self.dictionary[key_name] = []\n",
    "            self.dictionary[key_name].append(loss_dict[key_name])\n",
    "    \n",
    "    def fetch_dict(self):\n",
    "        return self.dictionary\n",
    "    \n",
    "class loss_aggregator():\n",
    "    def __init__(self):\n",
    "        super(loss_aggregator, self).__init__()\n",
    "        self.main_loss_dict = total_loss_list()\n",
    "        self.aggregated_dict = {}\n",
    "\n",
    "    def add(self, loss_dict):\n",
    "        self.main_loss_dict.update(loss_dict)\n",
    "\n",
    "    def aggregate(self):\n",
    "        for key in self.main_loss_dict.fetch_dict().keys():\n",
    "            self.aggregated_dict[key] = np.mean(self.main_loss_dict.fetch_dict()[key])\n",
    "\n",
    "        return self.aggregated_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {'f1':[1,2,3,4,5,6],'f2':[10,20,30,40,50,60]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1': 3.5, 'f2': 35.0}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_logger = loss_aggregator()\n",
    "loss_logger.add(losses)\n",
    "loss_logger.aggregate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
